# üöÄ Quick Start Guide - SecureNews

## Method 1: Automated Script (Recommended)

### macOS / Linux:
```bash
./run.sh
```

### Windows:
```batch
run.bat
```

The script will:
- ‚úÖ Check for Python and FFmpeg
- ‚úÖ Create virtual environment
- ‚úÖ Install all dependencies
- ‚úÖ Start the server

---

## Method 2: Manual Setup

### Step 1: Install Prerequisites

**macOS:**
```bash
brew install ffmpeg
```

**Linux:**
```bash
sudo apt-get update
sudo apt-get install ffmpeg
```

**Windows:**
Download FFmpeg from https://ffmpeg.org/download.html and add to PATH

### Step 2: Create Virtual Environment
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### Step 3: Install Dependencies
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### Step 4: Create Directories
```bash
mkdir -p uploads outputs
```

### Step 5: Run the Application
```bash
python app.py
```

---

## üåê Access the Application

Once the server starts (after models finish loading), open your browser:

**URL:** http://localhost:5001

---

## ‚è±Ô∏è First Run Timeline

- **Setup:** 2-5 minutes (installing packages)
- **Model Download:** 10-15 minutes (first run only)
  - Whisper model (~150MB)
  - NLLB-200 model (~1.2GB)
  - Sentence Transformers (~90MB)
- **Subsequent Runs:** 1-2 minutes (models cached)

---

## ‚úÖ Check Server Status

```bash
curl http://localhost:5001/api/health
```

Expected response when ready:
```json
{"status": "healthy", "models_loaded": true}
```

---

## üé¨ Using the Application

1. Open http://localhost:5001 in your browser
2. Upload a video file (MP4, AVI, MOV, MKV, or WAV)
3. Select source and target languages
4. Click "Translate Video"
5. Wait for processing (may take several minutes)
6. Download your translated video with embedded subtitles

---

## üõë Stop the Server

Press `Ctrl+C` in the terminal where the server is running.

---

## ‚ùì Troubleshooting

**Port 5001 already in use?**
- The app will show an error. Kill the process using port 5001 or change the port in `app.py`

**Models not downloading?**
- Check your internet connection
- Models download to `~/.cache/huggingface/`

**Out of memory?**
- Close other applications
- The models require ~2-3GB RAM

**FFmpeg errors?**
- Ensure FFmpeg is installed: `ffmpeg -version`
- On macOS: `brew install ffmpeg`

